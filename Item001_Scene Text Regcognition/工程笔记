2018-11-08
一、场景识别
  主要是《全景分割》
  https://mp.weixin.qq.com/s/8WKy9KTUp_U8UK8FAR78Jg
  GitHub地址：https://github.com/bei21/img2poem

  解决repo模型存在问题和修改方向性识别问题
  https://github.com/jiangxiluning/chinese-ocr
  DA-GAN
  Big-GAN
  《Large Scale GAN Training for High Fidelity Natural Image Synthesis》
  注意力机制模型RA-CNN
    《注意力与细粒度解决小目标问题》
    https://github.com/YapengTian/Single-Image-Super-Resolution
    《遮挡的和跨尺度检测问题》A-Faster-RCNN（Adversarial SpatialDropout Network）/ECCV2018的Bi-box行人遮挡检测及OR-CNN
  2、细粒度问题在图像和自然语言上应用
  3、注意力在语言和图像上应用
  4、图像的厚度问题，反卷积
  5、迁移学习
  6、强化学习、逆强化学习、后验推理
  7、多模态融合
  8、ICLR ：https://chillee.github.io
  变分鉴别器瓶颈（VDB）导致对抗性学习算法在三个不同应用领域得到显着改进
  https://chillee.github.io/OpenReviewExplorer/index.html?conf=iclr2019
  https://mp.weixin.qq.com/s/2rqwGRjl5YdP_rvkACkY4g

二、视频与3D图像分割与生成
   《多模态多光谱场景分割》
   ERL算法设计和流行学习、胶囊网络和拱形几何网络
  http://m.sohu.com/a/237503823_610300
  在github上已经有人用faster修改实现了视频的多维高速识别和编解码

sci-hub论文下载网站
  http://tool.yovisun.com/scihub/

keras版本的unet
https://blog.csdn.net/u012931582/article/details/70215756
倾斜书本的转正问题-透射变化+最小矩形检测
https://blog.csdn.net/mao_hui_fei/article/details/79729956
图像数据网络传输
https://blog.csdn.net/huhuang/article/details/54911982
python图像直方图
https://blog.csdn.net/yuyangyg/article/details/70857438
deeplabv3+训练笔记
https://blog.csdn.net/ncloveqy/article/details/82285106
https://python.ctolib.com/bonlime-keras-deeplab-v3-plus.html

深度学习论文路线学习笔记
https://github.com/SnailTyan/deep-learning-papers-translation
keras-yolo3-text
https://github.com/chineseocr/keras-yolo3-text
ICPR-2018——OCR笔记
https://blog.csdn.net/qq_14845119/article/details/82219246
SVHN
Text Recognition
https://bartzi.de/research/see

tensorflow版本STN——CNN——LSTM——CTC
https://github.com/Eric3911/STN_CNN_LSTM_CTC_TensorFlow

A文章来源：企鹅号 - CSIG文档图像分析与识别专委会
AAI 2018文档图像分析与识别相关论文选读
https://cloud.tencent.com/developer/news/154431
R2CNN
https://blog.csdn.net/u010183397/article/details/76473071
OCR系统论文
https://blog.csdn.net/jiachen0212/article/details/79498047
文本检测
https://zhuanlan.zhihu.com/p/37781277
https://github.com/bgshih/seglink
http://www.cnblogs.com/skyfsm/p/9776611.html
tensorflow不定长自然场景文本检测
https://blog.csdn.net/p312011150/article/details/82660072
文本检测
https://weibo.com/1560015614/GkLz1a4BH?type=comment
自然场景文本检测
https://blog.csdn.net/u011956004/article/details/79073282
Hypernet
https://segmentfault.com/a/1190000009030250
keras版本的Focal loss+Retinanet 
https://blog.csdn.net/u012426298/article/details/80450537
利用seglink训练自己的数据
https://blog.csdn.net/weixin_43122521/article/details/82558346
https://blog.csdn.net/u011440558/article/details/78564615
https://blog.csdn.net/jiachen0212/article/details/79471823?utm_source=blogxgwz1
DenseNet
tps://blog.csdn.net/qq_14845119/article/details/79272082
YOLT遥感图像识别
https://blog.csdn.net/bryant_meng/article/details/81284915
https://blog.csdn.net/jacke121/article/details/80531278
NasNet图像识别
https://blog.csdn.net/sparkexpert/article/details/79834704
遥感图像分割
基于segnet和Unet的语义分割
https://www.sohu.com/a/218292615_642762
Segnet训练自己的模型
https://blog.csdn.net/weixin_43122521/article/details/82558346
文本检测与OCR
https://weibo.com/1560015614/GkLz1a4BH?type=comment
https://zhuanlan.zhihu.com/p/37781277
https://weibo.com/1560015614/GkLz1a4BH?type=comment
https://zhuanlan.zhihu.com/p/37363942
tensorflow训练日志
https://www.urlteam.org/2017/09/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%EF%BC%9Atensorflow%E5%B0%8F%E7%99%BD%E5%AE%9E%E8%B7%B5/
https://blog.csdn.net/asukasmallriver/article/details/78752178
https://www.urlteam.org/2017/09/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%EF%BC%9Atensorflow%E5%B0%8F%E7%99%BD%E5%AE%9E%E8%B7%B5/
keras版本的GRU
https://blog.csdn.net/dcrmg/article/details/79306402
https://download.csdn.net/download/dcrmg/10248818
https://www.cnblogs.com/skyfsm/p/8029668.html
基于yolov3+CRNN的中文文字识别通用模型
https://swift.ctolib.com/article/comments/94721
动手学深度学习练习代码
https://github.com/SnailTyan/gluon-practice-code
opencv关键点检测
https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/
基于区域的全卷积神经网络
http://www.cnblogs.com/llfctt/p/9071889.html
图解CNN计算过程
https://blog.csdn.net/v_JULY_v/article/details/79434745?tdsourcetag=s_pcqq_aiomsg


图像旋转转正
import cv2	
import numpy as np
from PIL import Image
from skimage import transform
import matplotlib.pyplot as plt


def calc_length(point1, point2):
    x = (point1[0] - point2[0]) ** 2
    y = (point1[1] - point2[1]) ** 2
    return (x + y) ** 0.5

MIN_MATCH_COUNT = 10 
#标准的证件模板
dst_img = cv2.imread('C:/Users/Administrator/Desktop/1010test/1234567.jpg', 0)
#需要检测的证件读入路径
ori_img_ori = cv2.imread('C:/Users/Administrator/Desktop/1010test/123456.jpg', 1)
#使用SIFT检测角点
sift = cv2.xfeatures2d.SIFT_create()
# 获取关键点和描述符
kp1, des1 = sift.detectAndCompute(dst_img, None)
kp2, des2 = sift.detectAndCompute(ori_img_ori, None)

# 定义FLANN匹配器
index_params = dict(algorithm = 1, trees = 5)
search_params = dict(checks = 50)
flann = cv2.FlannBasedMatcher(index_params, search_params)
# 使用KNN算法匹配
matches = flann.knnMatch(des1,des2,k=2)

# 去除错误匹配
good = []
for m,n in matches:
    if m.distance < 0.9*n.distance:
        good.append(m)

# 单应性
print(len(good))
if len(good) > MIN_MATCH_COUNT:
    # 改变数组的表现形式，不改变数据内容，数据内容是每个关键点的坐标位置
    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)
    # findHomography 函数是计算变换矩阵
    # 参数cv2.RANSAC是使用RANSAC算法寻找一个最佳单应性矩阵H，即返回值M
    # 返回值：M 为变换矩阵，mask是掩模
    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)
    # ravel方法将数据降维处理，最后并转换成列表格式
    matchesMask = mask.ravel().tolist()
    # 获取img1的图像尺寸
    h,w = dst_img.shape
    # pts是图像img1的四个顶点
    pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)
    # 计算变换后的四个顶点坐标位置
    ori = cv2.perspectiveTransform(pts, M)

    dst = [(ele[0][0], ele[0][1]) for ele in ori]
    length_width = int(max(calc_length(dst[3], dst[0]), calc_length(dst[1], dst[2])))
    length_hight = int(max(calc_length(dst[0], dst[1]), calc_length(dst[2], dst[3])))
    tar = np.float32([[0,0],[length_hight,0],[length_hight,length_width], [0,length_width]])
    warp_matrix = cv2.getPerspectiveTransform(ori, tar)
    res = cv2.warpPerspective(ori_img_ori, warp_matrix, (length_hight, length_width))
    rot_img = transform.rotate(res[::-1,:], -90, resize=True)
    #img_new =cv2.resize(rot_img,(880,600),interpolation=cv2.INTER_CUBIC)
    result = cv2.imshow("WarpImg", rot_img)
    
else:
    print("Not enough matches are found - %d/%d") % (len(good),MIN_MATCH_COUNT)
    matchesMask = None
cv2.waitKey(0)





# -*- coding: utf-8 -*-
"""
Created on Fri Nov  2 11:39:31 2018

@author: Administrator
"""
#光斑检测问题
import cv2 as cv
import numpy as np

#全局阈值
def threshold_demo(image):
    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)  #把输入图像灰度化
    #直接阈值化是对输入的单通道矩阵逐像素进行阈值分割。
    ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_TRIANGLE)
    print("threshold value %s"%ret)
    cv.namedWindow("binary0", cv.WINDOW_NORMAL)
    cv.imshow("binary0", binary)

#局部阈值
def local_threshold(image):
    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)  #把输入图像灰度化
    #自适应阈值化能够根据图像不同区域亮度分布，改变阈值
    binary =  cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY, 25, 10)
    cv.namedWindow("binary1", cv.WINDOW_NORMAL)
    cv.imshow("binary1", binary)

#用户自己计算阈值
def custom_threshold(image):
    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)  #把输入图像灰度化
    h, w =gray.shape[:2]
    m = np.reshape(gray, [1,w*h])
    mean = m.sum()/(w*h)
    print("mean:",mean)
    ret, binary =  cv.threshold(gray, mean, 255, cv.THRESH_BINARY)
    cv.namedWindow("binary2", cv.WINDOW_NORMAL)
    cv.imshow("binary2", binary)

src = cv.imread('C:/Users/Administrator/Desktop/1010test/1102/光斑检测/1.jpg')
cv.namedWindow('input_image', cv.WINDOW_NORMAL) #设置为WINDOW_NORMAL可以任意缩放
cv.imshow('input_image', src)
threshold_demo(src)
local_threshold(src)
custom_threshold(src)
cv.waitKey(0)
cv.destroyAllWindows()




取虫子
import cv2
import numpy as np


def get_image(path):
    #获取图片
    img=cv2.imread(path)
    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    return img, gray

def Gaussian_Blur(gray):
    # 高斯去噪
    blurred = cv2.GaussianBlur(gray, (3, 3),0)

    return blurred

def Sobel_gradient(blurred):
    # 索比尔算子来计算x、y方向梯度
    gradX = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=1, dy=0)
    gradY = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=0, dy=1)

    gradient = cv2.subtract(gradX, gradY)
    gradient = cv2.convertScaleAbs(gradient)

    return gradX, gradY, gradient

def Thresh_and_blur(gradient):

    blurred = cv2.GaussianBlur(gradient, (9, 9),0)
    (_, thresh) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)

    return thresh

def image_morphology(thresh):
    # 建立一个椭圆核函数
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25))
    # 执行图像形态学, 细节直接查文档，很简单
    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    closed = cv2.erode(closed, None, iterations=4)
    closed = cv2.dilate(closed, None, iterations=4)

    return closed

def findcnts_and_box_point(closed):
    # 这里opencv3返回的是三个参数
    (_, cnts, _) = cv2.findContours(closed.copy(),
        cv2.RETR_LIST,
        cv2.CHAIN_APPROX_SIMPLE)
    c = sorted(cnts, key=cv2.contourArea, reverse=True)[0]
    # compute the rotated bounding box of the largest contour
    rect = cv2.minAreaRect(c)
    box = np.int0(cv2.boxPoints(rect))

    return box

def drawcnts_and_cut(original_img, box):
    # 因为这个函数有极强的破坏性，所有需要在img.copy()上画
    # draw a bounding box arounded the detected barcode and display the image
    draw_img = cv2.drawContours(original_img.copy(), [box], -1, (0, 0, 255), 3)

    Xs = [i[0] for i in box]
    Ys = [i[1] for i in box]
    x1 = min(Xs)
    x2 = max(Xs)
    y1 = min(Ys)
    y2 = max(Ys)
    hight = y2 - y1
    width = x2 - x1
    crop_img = original_img[y1:y1+hight, x1:x1+width]

    return draw_img, crop_img

def walk():

    img_path = r'C:/Users/Administrator/Desktop/1010test/123456.jpg'
    save_path = r'C:/Users/Administrator/Desktop/1010test/1678_save.png'
    original_img, gray = get_image(img_path)
    blurred = Gaussian_Blur(gray)
    gradX, gradY, gradient = Sobel_gradient(blurred)
    thresh = Thresh_and_blur(gradient)
    closed = image_morphology(thresh)
    box = findcnts_and_box_point(closed)
    draw_img, crop_img = drawcnts_and_cut(original_img,box)

    # 暴力一点，把它们都显示出来看看

    cv2.imshow('original_img', original_img)
    cv2.imshow('blurred', blurred)
    cv2.imshow('gradX', gradX)
    cv2.imshow('gradY', gradY)
    cv2.imshow('final', gradient)
    cv2.imshow('thresh', thresh)
    cv2.imshow('closed', closed)
    cv2.imshow('draw_img', draw_img)
    cv2.imwrite('draw_img',draw_img)
    cv2.imshow('crop_img', crop_img)
    cv2.waitKey(20171219)
    cv2.imwrite(save_path, crop_img)

walk()

#一、批量修改xml节点voc脚本
# coding=utf-8
import os
import os.path
import xml.dom.minidom

#获得文件夹中所有文件
FindPath = '/home/ubuntu/Desktop/myvoc2007/Annotations/'
FileNames = os.listdir(FindPath)
s = []
xml_path = '/home/ubuntu/Desktop/new/'
for file_name in FileNames:
    if not os.path.isdir(file_name):  # 判断是否是文件夹,不是文件夹才打开
        print file_name

    #读取xml文件
    dom = xml.dom.minidom.parse(os.path.join(FindPath,file_name))
    root = dom.documentElement

    # 获取标签对name之间的值
    name = root.getElementsByTagName('name')
    for i in range(len(name)):
        print name[i].firstChild.data
        if name[i] .firstChild.data== 'screw cap':
            name[i].firstChild.data = 'screwnut'
            print '修改后的 name'
            print name[i].firstChild.data
    #将修改后的xml文件保存
    with open(os.path.join(xml_path, file_name), 'w') as fh:
        dom.writexml(fh)
        print('写入name/pose OK!')
        
        
        
#二、图片文件批量重命名
import os

class ImageRename():
    def __init__(self):
        self.path = 'C:/yawning/'

    def rename(self):
        filelist = os.listdir(self.path)
        total_num = len(filelist)

        i = 0

        for item in filelist:
            if item.endswith('.jpg'):
                src = os.path.join(os.path.abspath(self.path), item)
                dst = os.path.join(os.path.abspath(self.path), '' + format(str(i), '0>3s') + '.jpg')
                os.rename(src, dst)
                print('conerting %s to %s ...' %(src,dst))
                i = i + 1
        print( 'total %d to rename & converted %d jpgs'%(total_num, i))

if __name__ == '__main__':
    newname = ImageRename()
    newname.rename()  
  
#三、爬取图像（以后尝试爬取视频）
import urllib.request
import re
def getHtml(url):
#url = urllib.parse.quote(url)
	page = urllib.request.urlopen(url)
	html = page.read()
	return html
def getImg(html):
	reg = 'src ="(.+?\.jpg)" alt='
	image = re.compile(reg)
	html =html.decode('utf-8') #python3
	imglist = re.findall(imgre,html)
	x  = 0
	for imgurl in imglist:
	urllib.request.urlretrieve(imgurl,'%s.jpg'% x)
	x+=1
	return imglist
html = getHtml("http://www.123.com/13.html")
print(getImg(html))



#四、将视频按照帧数转换成图片（一帧12张）
import cv2
vc = vc2.VideoCapture("initialD.mp4")
c=1
if vc.isOpened():
	rval,frame=vc.read()
else:
	rval=False
while rval:
	rval,frame=vc.read()
	cv2.imwrite('F://selffakeedataset//'+str(r)'.jpg',frame)
	c=c+1
	cv2.waitKey(1)
	vc.release()
  
  
#五、数据增强（通过旋转模糊和剪切将一张图片扩增为50张）
#https://github.com/aleju/imgaug
from keras.preprocessing.image import ImageDataGenerator，arry_to_img,img_to_array,load_img
	datagen = ImageDataGenerator(
	rotation_range=30,#参数为整数，图片随机转动的角度
	width_shift_range=0.2,#参数为浮点数，图片水平比例偏移的幅度
	height_shift_range =0.2,#参数为浮点数，图片竖直偏移的幅度
	shear_range=0.2,#参数为浮点数，逆时针方向剪切变换的角度
	zoom_range=0.2,#参数为浮点数，随机旋转的幅度
	horizontal_flip=Ture,#布尔值，进行随机水平翻转
	fil=mode='nearest')#参数为costant/nearest/reflect/wrap/，进行变化时候超出边界的点根据本参数的方法处理。
img = load_img('C:/users/train/000012''.jpg')#这是一个PIL图像
x = img_to_array(img)#把一个PIL图像转换成一个numpy数组形状为（3，150，150）
x = x.reshape((1,)+x.shape)#这是一个numpy数组形状为（1，3，150，150）
#下面是生成图像的代码
i = 0
for batch in datagen.flow(x,batch_size=1,save_to_dir='C:/PIC/',save_prefix='smoking',save_foramt='jpeg'):
	i += 1
	if i > 50:
	break #否则退出生成器循环。
  
  
  
#六、根据图片和xml文件扩增数据
import cv2
import math
import numpy as np
import xml.etree.ElemetTree as ET
import os

def rotate_imge(src,angle,scale=1):
	w = src.shape[1]
	h = src.shape[0]
	#将角度转化为弧度
	range=np.deg2rad(angle)
	#从新计算图片的宽度和高度
	nw=(abs(np.sin(angle)*h)+abs(np.cos(rangle)*w))*scale
	nh=(abs(np.cos(angle)*h)+abs(np.sin(rangle)*w))*scale
	#访问opencv的旋转矩阵
	rot_mat = cv2.getRotationMatrix2D(nw*0.5,nh*0.5),angle,scale)
	#随着旋转计算从旧中心到新中心
	rot_move = np.dot(rot_mat,np.arry([(nw - w)*0.5,(nh -h)*0.5,0]))
	#这部分的转秩只是为了更新部分的参数转秩更新
	rot_mat[0,2] += rot_move[0]
	rot_mat[1,2] += rot_move[1]
	dst =cv2.warpAffine(src,rot_mat,(int(math.ceil(nw)),int(math.ceil(nh))),flages=cv2.INTER_LANCZ0S4)
	#仿射变化
	return dst
	def rotate_xml(src,xmin,ymin,xmax,ymax,angle,scale=1.):
	w = src.shape[1]
	h = src.shape[0]
	rangle = np.deg2rad(angle)
	#将弧度转为角度，获取旋转后图像的宽度和长度。
	nw =(abs(np.sin(rangle)*h)+abs(np.cos(rangle)*w))*scale
	nh = (abs(np.cos(rangle)*h))+abs(np.sin(rangle)*w)*scale
	#访问opencv的旋转矩阵
	rot_mat = cv2.getRotationMatrix2D((nw*0.5,nh*0.5),angle,scale)
	#计算随着旋转从旧中心到新中心
	rot_move = np.dot(rot_mat,np.arry([(nw-w)*0.5,(nh-h)*0.5,0]))
	rot_mat[0,2] += rot_move[0]
	rot_mat[1,2] += rot_move[1]
	point1 = np.dot(rot_mat,np.arry([(xmin+xmax)/2,ymin,1]))
	point2 = np.dot(rot_mat,np.arry([xmax,(ymin=ymax)/2,1]))
	point3 = np.dot(rot_mat,np.arry([(xmin+xmax)/2,ymax,1]))
	point4 = np.dot(rot_mat,np.arry([xmin,(ymin+ymax)/2,1]))
	concat = np.vstack((point1,point2,point3,point4))
	#修改arry类型
	concat = concat.astype(np.int32)
	rx,ry,rw,rh = cv.boundingRect(concat)
	return rx,ry,rw,rh
	#源图像路径
	imgpath = 'c:/data/1/'
	#源图像对应的标注xml
	xmlpath = 'C:/data/2/'
	#旋转后图像存放路径
	rotated_imgpath ='c:/data/3/'
	#旋转后的xml存放路径
	rotated_xmlpath ='c:/data/4/'
	for angle in (180,360):
	for i in os.listdir(imgpath):
	a,b = os.path.splitext(i)
	img = cv2.imwrite(imgpath+a+'.jpg')
	rotated_img = rotated_imgpath(img,angle)
	cv2.imwrite(rotated_imgpath+a+''+str(angle)+'d.jpg',rotated_img)
	print(str(i)+'has been rotated for'+str(angle)+'。')
	tree = ET.parse(xmlpath+a+'.xml')
	root = tree.getroot()
	for box in root.iter('bndbox'):
	xmin = float(box.find('xmin').text)
	ymin = float(box.find('ymin').text)
	xmax = float(box.find('xmax').text)
	ymax = float(box.find('yamx').text)
	x,y,w,h = rotate_xml(img,xmin,ymin,xmax,ymax,angle)#可以使用该步骤查看转换后的参数是否正确
	
	box.find('xmin').text = str(x)
	box.find('ymin').text = str(y)
    box.find('xmax').text = str(x+w)
	box.find('ymax').text = str(y+h)
    tree.write(rotate_xmlpath+a+'_'+str(angle)+'d.xml')
	print(str(a)+'.xml has been rotated for'+str(angle)+'。')
	
#七通过四个点坐标提起区域其他背景全mask为黑

# scale的问题  图片宽高scale多少，咱们的框也相应scale多少就行



import numpy as np
import cv2

# 读取原始图像
img = cv2.imread('./sample.jpg')

# 显示图像
cv2.imshow("original", img)

# 定义roi列表,按(xmin,xmax,ymin,ymax)格式存放所有roi
roi_list = list()

# rois的ndarray对象
# 四个顶点坐标:依次为左上,右上,右下,左下
# 取roi区域时,只需要知道xmin,xmax,ymin,ymax即可,对应左上和右下的两个点
rois = np.array([
    [[14, 29], [499, 29], [499, 44], [14, 44]],
    [[66, 63], [275, 63], [275, 105], [66, 105]]
    ])

# 遍历rois的ndarray对象,按照指定格式存入roi_list
# 第一种方式:取第1个点和第3个点
# 局限性:只对顺时针有效
# for roi in rois:
#     roi_list.append((roi[0][0], roi[2][0], roi[0][1], roi[2][1]))

# 第二种方式:直接使用最大最小值来取
# 优点:不用管各个点的顺序是顺时针或者逆时针.无序也可
# 局限性:必须是矩形的四个顶点
for roi in rois:
    xmin = np.min([coordinates[0] for coordinates in roi])
    xmax = np.max([coordinates[0] for coordinates in roi])
    ymin = np.min([coordinates[1] for coordinates in roi])
    ymax = np.max([coordinates[1] for coordinates in roi])
    roi_list.append((xmin, xmax, ymin, ymax))

# 构建一个新的结果图像
result = np.zeros_like(img)

# 取原始图像中取对应roi数据,赋值给结果图像对应位置,注意y在前x在后
for roi in roi_list:
    result[roi[2]:roi[3], roi[0]:roi[1]] = img[roi[2]:roi[3], roi[0]:roi[1]]

# 显示结果图像
cv2.imshow("result", result)
cv2.waitKey(0)


#八XML与txt的转换
#!/usr/bin/env python
# coding:utf-8
from lxml.etree import Element, SubElement, tostring
from xml.dom.minidom import parseString
import glob
import os
from PIL import Image
from tqdm import tqdm
def txtToXml(image_path, txt_path):
    for txt_file in tqdm(glob.glob(txt_path + '/*.txt')):
        txt_name_ = txt_file.split('\\')[-1][:-4]
        data = {"shapes": []}
        im = Image.open(image_path + '\\' + txt_name_ +'.jpg')
        width = im.size[0]
        height = im.size[1]
        tree = open(txt_file, 'r', encoding='UTF-8')
        node_root = Element('annotation')
        node_folder = SubElement(node_root, 'folder')
        node_folder.text = 'ICPR'
        node_filename = SubElement(node_root, 'filename')
        node_filename.text = txt_name_+ '.jpg'
        node_size = SubElement(node_root, 'size')
        node_width = SubElement(node_size, 'width')
        node_width.text = str(width)
        node_height = SubElement(node_size, 'height')
        node_height.text = str(height)
        node_depth = SubElement(node_size, 'depth')
        node_depth.text = '3'
        root = tree.readlines()
        for i, line in enumerate(root):
            column = line.split(',')
            node_object = SubElement(node_root, 'object')
            node_name = SubElement(node_object, 'name')
            node_name.text = 'text'    #做的是第二个项目，所以就把文本统一成了text
            node_difficult = SubElement(node_object, 'difficult')
            node_difficult.text = '0'
            node_bndbox = SubElement(node_object, 'bndbox')
            node_xmin = SubElement(node_bndbox, 'x0')
            node_xmin.text = column[0]
            node_ymin = SubElement(node_bndbox, 'y0')
            node_ymin.text = column[1]
            node_xmax = SubElement(node_bndbox, 'x1')
            node_xmax.text = column[2]
            node_ymax = SubElement(node_bndbox, 'y1')
            node_ymax.text = column[3]
            node_xmin = SubElement(node_bndbox, 'x2')
            node_xmin.text = column[4]
            node_ymin = SubElement(node_bndbox, 'y2')
            node_ymin.text = column[5]
            node_xmax = SubElement(node_bndbox, 'x3')
            node_xmax.text = column[6]
            node_ymax = SubElement(node_bndbox, 'y3')
            node_ymax.text = column[7]
        xml = tostring(node_root, pretty_print=True)  #格式化显示，该换行的换行
        dom = parseString(xml)
        with open(txt_name_ + '.xml', 'w') as f:
            dom.writexml(f, indent='\t', addindent='\t', newl='\n', encoding="utf-8")
 
 
if __name__ == "__main__":
    data_path = os.path.join(os.getcwd(), 'txt_1000')
    pic_path = os.path.join(os.getcwd(), 'image_1000')
    txtToXml(pic_path, data_path )


八、 
import cv2
import numpy as np
import matplotlib.pyplot as plt

img = cv2.imread('C:/Users/Administrator/Desktop/15.jpg',1)

#第一个为纵坐标参数，第二个为横坐标
points = np.array([[50, 1], [1, 50], [98, 98], [98, 1]])

cv2.fillConvexPoly(img, points,1)
plt.imshow(img, cmap='gray')
plt.show()

#一、批量修改xml节点voc脚本
# coding=utf-8
import os
import os.path
import xml.dom.minidom

#获得文件夹中所有文件
FindPath = '/home/ubuntu/Desktop/myvoc2007/Annotations/'
FileNames = os.listdir(FindPath)
s = []
xml_path = '/home/ubuntu/Desktop/new/'
for file_name in FileNames:
    if not os.path.isdir(file_name):  # 判断是否是文件夹,不是文件夹才打开
        print file_name

    #读取xml文件
    dom = xml.dom.minidom.parse(os.path.join(FindPath,file_name))
    root = dom.documentElement

    # 获取标签对name之间的值
    name = root.getElementsByTagName('name')
    for i in range(len(name)):
        print name[i].firstChild.data
        if name[i] .firstChild.data== 'screw cap':
            name[i].firstChild.data = 'screwnut'
            print '修改后的 name'
            print name[i].firstChild.data
    #将修改后的xml文件保存
    with open(os.path.join(xml_path, file_name), 'w') as fh:
        dom.writexml(fh)
        print('写入name/pose OK!')
        
        
        
#二、图片文件批量重命名
import os

class ImageRename():
    def __init__(self):
        self.path = 'C:/yawning/'

    def rename(self):
        filelist = os.listdir(self.path)
        total_num = len(filelist)

        i = 0

        for item in filelist:
            if item.endswith('.jpg'):
                src = os.path.join(os.path.abspath(self.path), item)
                dst = os.path.join(os.path.abspath(self.path), '' + format(str(i), '0>3s') + '.jpg')
                os.rename(src, dst)
                print('conerting %s to %s ...' %(src,dst))
                i = i + 1
        print( 'total %d to rename & converted %d jpgs'%(total_num, i))

if __name__ == '__main__':
    newname = ImageRename()
    newname.rename()  
  
#三、爬取图像（以后尝试爬取视频）
import urllib.request
import re
def getHtml(url):
#url = urllib.parse.quote(url)
	page = urllib.request.urlopen(url)
	html = page.read()
	return html
def getImg(html):
	reg = 'src ="(.+?\.jpg)" alt='
	image = re.compile(reg)
	html =html.decode('utf-8') #python3
	imglist = re.findall(imgre,html)
	x  = 0
	for imgurl in imglist:
	urllib.request.urlretrieve(imgurl,'%s.jpg'% x)
	x+=1
	return imglist
html = getHtml("http://www.123.com/13.html")
print(getImg(html))



#四、将视频按照帧数转换成图片（一帧12张）
import cv2
vc = vc2.VideoCapture("initialD.mp4")
c=1
if vc.isOpened():
	rval,frame=vc.read()
else:
	rval=False
while rval:
	rval,frame=vc.read()
	cv2.imwrite('F://selffakeedataset//'+str(r)'.jpg',frame)
	c=c+1
	cv2.waitKey(1)
	vc.release()
  
  
#五、数据增强（通过旋转模糊和剪切将一张图片扩增为50张）
#https://github.com/aleju/imgaug
from keras.preprocessing.image import ImageDataGenerator，arry_to_img,img_to_array,load_img
	datagen = ImageDataGenerator(
	rotation_range=30,#参数为整数，图片随机转动的角度
	width_shift_range=0.2,#参数为浮点数，图片水平比例偏移的幅度
	height_shift_range =0.2,#参数为浮点数，图片竖直偏移的幅度
	shear_range=0.2,#参数为浮点数，逆时针方向剪切变换的角度
	zoom_range=0.2,#参数为浮点数，随机旋转的幅度
	horizontal_flip=Ture,#布尔值，进行随机水平翻转
	fil=mode='nearest')#参数为costant/nearest/reflect/wrap/，进行变化时候超出边界的点根据本参数的方法处理。
img = load_img('C:/users/train/000012''.jpg')#这是一个PIL图像
x = img_to_array(img)#把一个PIL图像转换成一个numpy数组形状为（3，150，150）
x = x.reshape((1,)+x.shape)#这是一个numpy数组形状为（1，3，150，150）
#下面是生成图像的代码
i = 0
for batch in datagen.flow(x,batch_size=1,save_to_dir='C:/PIC/',save_prefix='smoking',save_foramt='jpeg'):
	i += 1
	if i > 50:
	break #否则退出生成器循环。
  
  
  
#六、根据图片和xml文件扩增数据
import cv2
import math
import numpy as np
import xml.etree.ElemetTree as ET
import os

def rotate_imge(src,angle,scale=1):
	w = src.shape[1]
	h = src.shape[0]
	#将角度转化为弧度
	range=np.deg2rad(angle)
	#从新计算图片的宽度和高度
	nw=(abs(np.sin(angle)*h)+abs(np.cos(rangle)*w))*scale
	nh=(abs(np.cos(angle)*h)+abs(np.sin(rangle)*w))*scale
	#访问opencv的旋转矩阵
	rot_mat = cv2.getRotationMatrix2D(nw*0.5,nh*0.5),angle,scale)
	#随着旋转计算从旧中心到新中心
	rot_move = np.dot(rot_mat,np.arry([(nw - w)*0.5,(nh -h)*0.5,0]))
	#这部分的转秩只是为了更新部分的参数转秩更新
	rot_mat[0,2] += rot_move[0]
	rot_mat[1,2] += rot_move[1]
	dst =cv2.warpAffine(src,rot_mat,(int(math.ceil(nw)),int(math.ceil(nh))),flages=cv2.INTER_LANCZ0S4)
	#仿射变化
	return dst
	def rotate_xml(src,xmin,ymin,xmax,ymax,angle,scale=1.):
	w = src.shape[1]
	h = src.shape[0]
	rangle = np.deg2rad(angle)
	#将弧度转为角度，获取旋转后图像的宽度和长度。
	nw =(abs(np.sin(rangle)*h)+abs(np.cos(rangle)*w))*scale
	nh = (abs(np.cos(rangle)*h))+abs(np.sin(rangle)*w)*scale
	#访问opencv的旋转矩阵
	rot_mat = cv2.getRotationMatrix2D((nw*0.5,nh*0.5),angle,scale)
	#计算随着旋转从旧中心到新中心
	rot_move = np.dot(rot_mat,np.arry([(nw-w)*0.5,(nh-h)*0.5,0]))
	rot_mat[0,2] += rot_move[0]
	rot_mat[1,2] += rot_move[1]
	point1 = np.dot(rot_mat,np.arry([(xmin+xmax)/2,ymin,1]))
	point2 = np.dot(rot_mat,np.arry([xmax,(ymin=ymax)/2,1]))
	point3 = np.dot(rot_mat,np.arry([(xmin+xmax)/2,ymax,1]))
	point4 = np.dot(rot_mat,np.arry([xmin,(ymin+ymax)/2,1]))
	concat = np.vstack((point1,point2,point3,point4))
	#修改arry类型
	concat = concat.astype(np.int32)
	rx,ry,rw,rh = cv.boundingRect(concat)
	return rx,ry,rw,rh
	#源图像路径
	imgpath = 'c:/data/1/'
	#源图像对应的标注xml
	xmlpath = 'C:/data/2/'
	#旋转后图像存放路径
	rotated_imgpath ='c:/data/3/'
	#旋转后的xml存放路径
	rotated_xmlpath ='c:/data/4/'
	for angle in (180,360):
	for i in os.listdir(imgpath):
	a,b = os.path.splitext(i)
	img = cv2.imwrite(imgpath+a+'.jpg')
	rotated_img = rotated_imgpath(img,angle)
	cv2.imwrite(rotated_imgpath+a+''+str(angle)+'d.jpg',rotated_img)
	print(str(i)+'has been rotated for'+str(angle)+'。')
	tree = ET.parse(xmlpath+a+'.xml')
	root = tree.getroot()
	for box in root.iter('bndbox'):
	xmin = float(box.find('xmin').text)
	ymin = float(box.find('ymin').text)
	xmax = float(box.find('xmax').text)
	ymax = float(box.find('yamx').text)
	x,y,w,h = rotate_xml(img,xmin,ymin,xmax,ymax,angle)#可以使用该步骤查看转换后的参数是否正确
	
	box.find('xmin').text = str(x)
	box.find('ymin').text = str(y)
    box.find('xmax').text = str(x+w)
	box.find('ymax').text = str(y+h)
    tree.write(rotate_xmlpath+a+'_'+str(angle)+'d.xml')
	print(str(a)+'.xml has been rotated for'+str(angle)+'。')
	
#七通过四个点坐标提起区域其他背景全mask为黑

# scale的问题  图片宽高scale多少，咱们的框也相应scale多少就行



import numpy as np
import cv2

# 读取原始图像
img = cv2.imread('./sample.jpg')

# 显示图像
cv2.imshow("original", img)

# 定义roi列表,按(xmin,xmax,ymin,ymax)格式存放所有roi
roi_list = list()

# rois的ndarray对象
# 四个顶点坐标:依次为左上,右上,右下,左下
# 取roi区域时,只需要知道xmin,xmax,ymin,ymax即可,对应左上和右下的两个点
rois = np.array([
    [[14, 29], [499, 29], [499, 44], [14, 44]],
    [[66, 63], [275, 63], [275, 105], [66, 105]]
    ])

# 遍历rois的ndarray对象,按照指定格式存入roi_list
# 第一种方式:取第1个点和第3个点
# 局限性:只对顺时针有效
# for roi in rois:
#     roi_list.append((roi[0][0], roi[2][0], roi[0][1], roi[2][1]))

# 第二种方式:直接使用最大最小值来取
# 优点:不用管各个点的顺序是顺时针或者逆时针.无序也可
# 局限性:必须是矩形的四个顶点
for roi in rois:
    xmin = np.min([coordinates[0] for coordinates in roi])
    xmax = np.max([coordinates[0] for coordinates in roi])
    ymin = np.min([coordinates[1] for coordinates in roi])
    ymax = np.max([coordinates[1] for coordinates in roi])
    roi_list.append((xmin, xmax, ymin, ymax))

# 构建一个新的结果图像
result = np.zeros_like(img)

# 取原始图像中取对应roi数据,赋值给结果图像对应位置,注意y在前x在后
for roi in roi_list:
    result[roi[2]:roi[3], roi[0]:roi[1]] = img[roi[2]:roi[3], roi[0]:roi[1]]

# 显示结果图像
cv2.imshow("result", result)
cv2.waitKey(0)


#八XML与txt的转换
#!/usr/bin/env python
# coding:utf-8
from lxml.etree import Element, SubElement, tostring
from xml.dom.minidom import parseString
import glob
import os
from PIL import Image
from tqdm import tqdm
def txtToXml(image_path, txt_path):
    for txt_file in tqdm(glob.glob(txt_path + '/*.txt')):
        txt_name_ = txt_file.split('\\')[-1][:-4]
        data = {"shapes": []}
        im = Image.open(image_path + '\\' + txt_name_ +'.jpg')
        width = im.size[0]
        height = im.size[1]
        tree = open(txt_file, 'r', encoding='UTF-8')
        node_root = Element('annotation')
        node_folder = SubElement(node_root, 'folder')
        node_folder.text = 'ICPR'
        node_filename = SubElement(node_root, 'filename')
        node_filename.text = txt_name_+ '.jpg'
        node_size = SubElement(node_root, 'size')
        node_width = SubElement(node_size, 'width')
        node_width.text = str(width)
        node_height = SubElement(node_size, 'height')
        node_height.text = str(height)
        node_depth = SubElement(node_size, 'depth')
        node_depth.text = '3'
        root = tree.readlines()
        for i, line in enumerate(root):
            column = line.split(',')
            node_object = SubElement(node_root, 'object')
            node_name = SubElement(node_object, 'name')
            node_name.text = 'text'    #做的是第二个项目，所以就把文本统一成了text
            node_difficult = SubElement(node_object, 'difficult')
            node_difficult.text = '0'
            node_bndbox = SubElement(node_object, 'bndbox')
            node_xmin = SubElement(node_bndbox, 'x0')
            node_xmin.text = column[0]
            node_ymin = SubElement(node_bndbox, 'y0')
            node_ymin.text = column[1]
            node_xmax = SubElement(node_bndbox, 'x1')
            node_xmax.text = column[2]
            node_ymax = SubElement(node_bndbox, 'y1')
            node_ymax.text = column[3]
            node_xmin = SubElement(node_bndbox, 'x2')
            node_xmin.text = column[4]
            node_ymin = SubElement(node_bndbox, 'y2')
            node_ymin.text = column[5]
            node_xmax = SubElement(node_bndbox, 'x3')
            node_xmax.text = column[6]
            node_ymax = SubElement(node_bndbox, 'y3')
            node_ymax.text = column[7]
        xml = tostring(node_root, pretty_print=True)  #格式化显示，该换行的换行
        dom = parseString(xml)
        with open(txt_name_ + '.xml', 'w') as f:
            dom.writexml(f, indent='\t', addindent='\t', newl='\n', encoding="utf-8")
 
 
if __name__ == "__main__":
    data_path = os.path.join(os.getcwd(), 'txt_1000')
    pic_path = os.path.join(os.getcwd(), 'image_1000')
    txtToXml(pic_path, data_path )


八、 
import cv2
import numpy as np
import matplotlib.pyplot as plt

img = cv2.imread('C:/Users/Administrator/Desktop/15.jpg',1)

#第一个为纵坐标参数，第二个为横坐标
points = np.array([[50, 1], [1, 50], [98, 98], [98, 1]])

cv2.fillConvexPoly(img, points,1)
plt.imshow(img, cmap='gray')
plt.show()

一、python模板匹配算法（该算法对相似度的要求极高并且不支持任意角度）

import cv2 as cv
import numpy as np

def template_demo():
    #读取模板图像
    tpl = cv.imread("D:/1110/9.png")
    #读取实例图像
    target = cv.imread("D:/1110/7.png")
    #cv.imshow("template image",tpl)
    #cv.imshow("target image",target)
    # 匹配方法 ：平方差匹配、相关性匹配、相关性系数（相关性是越接近1越大越好，）
    methods = [cv.TM_SQDIFF_NORMED,cv.TM_CCORR_NORMED,cv.TM_CCOEFF_NORMED]
    th,tw = tpl.shape[:2]
    for md in methods:
        result = cv.matchTemplate(target,tpl,md)
        # result是我们各种算法下匹配后的图像
        #cv.imshow("%s"%md,result)
        #获取的是每种公式中计算出来的值，每个像素点都对应一个值
        min_val,max_val,min_loc,max_loc = cv.minMaxLoc(result)
        if md == cv.TM_SQDIFF_NORMED:
            tl = min_loc    #tl是左上角点
        else:
            tl = max_loc
        br = (tl[0]+tw,tl[1]+th)    #右下点
        cv.rectangle(target,tl,br,(0,0,255),2)
        cv.imshow("match-%s"%md,target)

src = cv.imread("D:/1110/9.png")  #读取图片
cv.namedWindow("input image",cv.WINDOW_AUTOSIZE)    #创建GUI窗口,形式为自适应
cv.imshow("input image",src)    #通过名字将图像和窗口联系
template_demo()
cv.waitKey(0)   #等待用户操作，里面等待参数是毫秒，我们填写0，代表是永远，等待用户操作
cv.destroyAllWindows()  #销毁所有窗口


二、自由视角模板匹配模型

import numpy as np
import cv2
from skimage import transform

def calc_length(point1, point2):
    x = (point1[0] - point2[0]) ** 2
    y = (point1[1] - point2[1]) ** 2
    return (x + y) ** 0.5
#阈值参数
MIN_MATCH_COUNT = 10
#标准的证件模板
dst_img = cv2.imread('C:/Users/Administrator/Desktop/1010test/1.jpg', 0)
#需要检测的证件读入路径
ori_img_ori = cv2.imread('C:/Users/Administrator/Desktop/1010test/canny1.jpg', 1)
# 使用SIFT检测角点
sift = cv2.xfeatures2d.SIFT_create()
# 获取关键点和描述符
kp1, des1 = sift.detectAndCompute(dst_img, None)
kp2, des2 = sift.detectAndCompute(ori_img_ori, None)

# 定义FLANN匹配器
index_params = dict(algorithm = 1, trees = 5)
search_params = dict(checks = 50)
flann = cv2.FlannBasedMatcher(index_params, search_params)
# 使用KNN算法匹配
matches = flann.knnMatch(des1,des2,k=2)

# 去除错误匹配
good = []
for m,n in matches:
    if m.distance < 0.7*n.distance:
        good.append(m)

# 单应性
if len(good) > MIN_MATCH_COUNT:
    # 改变数组的表现形式，不改变数据内容，数据内容是每个关键点的坐标位置
    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)
    # findHomography 函数是计算变换矩阵
    # 参数cv2.RANSAC是使用RANSAC算法寻找一个最佳单应性矩阵H，即返回值M
    # 返回值：M 为变换矩阵，mask是掩模
    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)
    # ravel方法将数据降维处理，最后并转换成列表格式
    matchesMask = mask.ravel().tolist()
    # 获取img1的图像尺寸
    h,w = dst_img.shape
    # pts是图像img1的四个顶点
    pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)
    # 计算变换后的四个顶点坐标位置
    ori = cv2.perspectiveTransform(pts, M)

    dst = [(ele[0][0], ele[0][1]) for ele in ori]
    length_width = int(max(calc_length(dst[3], dst[0]), calc_length(dst[1], dst[2])))
    length_hight = int(max(calc_length(dst[0], dst[1]), calc_length(dst[2], dst[3])))
    tar = np.float32([[0,0],[length_hight,0],[length_hight,length_width], [0,length_width]])
    warp_matrix = cv2.getPerspectiveTransform(ori, tar)
    res = cv2.warpPerspective(ori_img_ori, warp_matrix, (length_hight, length_width))
    rot_img = transform.rotate(res[::-1,:], -90, resize=True)
    result = cv2.imshow("WarpImg", rot_img)
    cv2.imwrite('C:/Users/Administrator/Desktop/1010test/WarpImg.png',rot_img)
    res = cv2.imread('C:/Users/Administrator/Desktop/1010test/WarpImg.png')
    dst1 = cv2.resize(res,(880,600),interpolation=cv2.INTER_CUBIC)

    # # 根据四个顶点坐标位置在源图像画出找到的边框
    # ori_img = cv2.polylines(ori_img,[np.int32(dst)],True,(255,0,0),3, cv2.LINE_AA)
    # cv2.imshow('findu', ori_img)
else:
    print("Not enough matches are found - %d/%d") % (len(good),MIN_MATCH_COUNT)
    matchesMask = None
    
   三、兴趣区域检测
   
   import numpy as np
import cv2

#读取图片
img = cv2.imread('C:/Users/Administrator/Desktop/1010test/16.jpg')
#二值化，canny检测
img = cv2.GaussianBlur(img,(3,3),0)
binaryImg = cv2.Canny(img,10,150)
#寻找轮廓
#也可以这么写：binary,contours, hierarchy = cv2.findContours(binaryImg,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
#这样，可以直接用contours表示
h = cv2.findContours(binaryImg,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)
#提取轮廓
contours = h[1]
#打印返回值，这是一个元组
print(type(h))
#打印轮廓类型，这是个列表
print(type(h[1]))
#查看轮廓数量
print (len(contours))

#创建白色幕布
temp = np.ones(binaryImg.shape,np.uint8)*255
#画出轮廓：temp是白色幕布，contours是轮廓，-1表示全画，然后是颜色，厚度
cv2.drawContours(temp,contours,-1,(0,255,0),3)

cv2.imshow("contours",temp)
cv2.waitKey(0)
cv2.destroyAllWindows()

四、霍夫曼概率直线投票实现白纸转正问题纸张（仿射变换问题）

import cv2
import numpy as np

img = cv2.imread("C:/Users/Administrator/Desktop/1010test/16.jpg")

img = cv2.GaussianBlur(img,(3,3),0)
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

edges = cv2.Canny(gray,50,150,apertureSize = 3)
result1 = cv2.imwrite("canny.jpg", edges)
#霍夫曼概率投票之间检测获得兴趣区域
lines = cv2.HoughLinesP(edges,1,np.pi/180,50,minLineLength=90,maxLineGap=10)
result2 = 0
img1 = cv2.GaussianBlur(img,(3,3),0)
for i in range(9):
    for x1,y1,x2,y2 in lines[i]:
        result2 = cv2.line(img1,(x1,y1),(x2,y2),(0,0,255),1)
        cv2.imwrite("canny1.jpg", result2)

result3 = cv2.circle(img,(207,151),2,(0,255,0),2)

result3 = cv2.circle(result3,(517,285),2,(0,255,0),2)
result3 = cv2.circle(result3,(17,601),2,(0,255,0),2)
result3 = cv2.circle(result3,(343,731),2,(0,255,0),2)
cv2.imwrite("canny2.jpg", result3)

img = cv2.imread("C:/Users/Administrator/Desktop/1010test/16.jpg")
src = np.float32([[207, 151], [517, 285], [17, 601], [343, 731]])
dst = np.float32([[0, 0], [337, 0], [0, 488], [337, 488]])
m = cv2.getPerspectiveTransform(src, dst)
result = cv2.warpPerspective(img, m, (337, 488))
cv2.imwrite("canny3.jpg", result)
cv2.waitKey(0)
cv2.destroyAllWindows()

五、#提取矩形的边框返回四个顶点参数

import numpy as np
import cv2
import os
im = cv2.imread('/home/csnt-dlu/Desktop/lc/project/canny.jpg')
imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
ret,thresh = cv2.threshold(imgray,127,255,0)
image, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

for i in range(0,len(contours)):
    x, y, w, h = cv2.boundingRect(contours[i])
    cv2.rectangle(image, (x,y), (x+w,y+h), (153,153,0), 5)

    newimage=image[y+2:y+h-2,x+2:x+w-2] # 先用y确定高，再用x确定宽
    nrootdir=("./")
    if not os.path.isdir(nrootdir):
        os.makedirs(nrootdir)
    cv2.imwrite( nrootdir+str(i)+".jpg",newimage)
    print(i)

六、圆形的检测

import numpy as np
import matplotlib.pyplot as plt
from skimage import measure,draw

#生成二值测试图像
img=np.zeros([100,100])
img[20:40,60:80]=1  #矩形
rr,cc=draw.circle(60,60,10)  #小圆
rr1,cc1=draw.circle(20,30,15) #大圆
img[rr,cc]=1
img[rr1,cc1]=1

#检测所有图形的轮廓
contours = measure.find_contours(img, 0.5)

#绘制轮廓
fig, (ax0,ax1) = plt.subplots(1,2,figsize=(8,8))
ax0.imshow(img,plt.cm.gray)
ax1.imshow(img,plt.cm.gray)
for n, contour in enumerate(contours):
    ax1.plot(contour[:, 1], contour[:, 0], linewidth=2)
ax1.axis('C:/Users/Administrator/Desktop/1010test/1.png',0)
ax1.set_xticks([])
ax1.set_yticks([])
plt.show()

七、空间书本转正问题（透射变换）
#1、解决了手机的稍微倾斜问题仿透射变换
import cv2
import numpy as np
def rad(x):
    return x * np.pi / 180

img = cv2.imread("C:/Users/Administrator/Desktop/1010test/21.jpg")
#cv2.imshow("original", img)

img = cv2.copyMakeBorder(img, 200, 200, 200, 200, cv2.BORDER_CONSTANT, 0)
w, h = img.shape[0:2]

anglex =-10
angley = 0
anglez = 0
fov = 42
while 1:
    # 镜头与图像间的距离，21为半可视角，算z的距离是为了保证在此可视角度下恰好显示整幅图像
    z = np.sqrt(w ** 2 + h ** 2) / 2 / np.tan(rad(fov / 2))
    # 齐次变换矩阵
    rx = np.array([[1, 0, 0, 0],
                   [0, np.cos(rad(anglex)), -np.sin(rad(anglex)), 0],
                   [0, -np.sin(rad(anglex)), np.cos(rad(anglex)), 0, ],
                   [0, 0, 0, 1]], np.float32)

    ry = np.array([[np.cos(rad(angley)), 0, np.sin(rad(angley)), 0],
                   [0, 1, 0, 0],
                   [-np.sin(rad(angley)), 0, np.cos(rad(angley)), 0, ],
                   [0, 0, 0, 1]], np.float32)

    rz = np.array([[np.cos(rad(anglez)), np.sin(rad(anglez)), 0, 0],
                   [-np.sin(rad(anglez)), np.cos(rad(anglez)), 0, 0],
                   [0, 0, 1, 0],
                   [0, 0, 0, 1]], np.float32)

    r = rx.dot(ry).dot(rz)

    # 四对点的生成
    pcenter = np.array([h / 2, w / 2, 0, 0], np.float32)

    p1 = np.array([0, 0, 0, 0], np.float32) - pcenter
    p2 = np.array([w, 0, 0, 0], np.float32) - pcenter
    p3 = np.array([0, h, 0, 0], np.float32) - pcenter
    p4 = np.array([w, h, 0, 0], np.float32) - pcenter

    dst1 = r.dot(p1)
    dst2 = r.dot(p2)
    dst3 = r.dot(p3)
    dst4 = r.dot(p4)

    list_dst = [dst1, dst2, dst3, dst4]

    org = np.array([[0, 0],
                    [w, 0],
                    [0, h],
                    [w, h]], np.float32)

    dst = np.zeros((4, 2), np.float32)

    # 投影至成像平面
    for i in range(4):
        dst[i, 0] = list_dst[i][0] * z / (z - list_dst[i][2]) + pcenter[0]
        dst[i, 1] = list_dst[i][1] * z / (z - list_dst[i][2]) + pcenter[1]

    warpR = cv2.getPerspectiveTransform(org, dst)

    result = cv2.warpPerspective(img, warpR, (h, w))
    cv2.imshow("result", result)
    c = cv2.waitKey(0)

    # anglex += 3            #auto rotate
    # anglez += 1             #auto rotate
    # angley += 2            #auto rotate

    # 键盘控制
    if 27 == c:  # Esc quit
        break;
    if c == ord('w'):
        anglex += 1
    if c == ord('s'):
        anglex -= 1
    if c == ord('a'):
        angley += 1
        # dx=0
    if c == ord('d'):
        angley -= 1
    if c == ord('u'):
        anglez += 1
    if c == ord('p'):
        anglez -= 1
    if c == ord('t'):
        fov += 1
    if c == ord('r'):
        fov -= 1
    if c == ord(' '):
        anglex = angley = anglez = 0
    if c == ord('q'):
        print("==============")
        print('旋转矩阵：\n', r)
        print("angle alpha: ", anglex, 'angle beta: ', angley, "dz: ", anglez, ": ", z)

cv2.destroyAllWindows()

八、边缘检测（直线检测提取矩形）
# coding=utf-8
import cv2
import numpy as np

img = cv2.imread("C:/Users/Administrator/Desktop/1010test/16.jpg")

img = cv2.GaussianBlur(img, (3, 3), 0)
edges = cv2.Canny(img, 50, 100, apertureSize=3)
lines = cv2.HoughLines(edges, 1, np.pi / 180, 118)  # 这里对最后一个参数使用了经验型的值
result = img.copy()
for line in lines[0]:
    rho = line[0]  # 第一个元素是距离rho
    theta = line[1]  # 第二个元素是角度theta
    if (theta < (np.pi / 4.)) or (theta > (3. * np.pi / 4.0)):  # 垂直直线
        # 该直线与第一行的交点
        pt1 = (int(rho / np.cos(theta)), 0)
        # 该直线与最后一行的焦点
        pt2 = (int((rho - result.shape[0] * np.sin(theta)) / np.cos(theta)), result.shape[0])
        # 绘制一条白线
        cv2.line(result, pt1, pt2, (255))
    else:  # 水平直线
        # 该直线与第一列的交点
        pt1 = (0, int(rho / np.sin(theta)))
        # 该直线与最后一列的交点
        pt2 = (result.shape[1], int((rho - result.shape[1] * np.cos(theta)) / np.sin(theta)))
        # 绘制一条直线
        cv2.line(result, pt1, pt2, (255), 1)

#cv2.imshow('Canny', edges)
cv2.imshow('Result', result)
cv2.waitKey(0)
cv2.destroyAllWindows()

九、harr角点检测

#角点检测
import cv2
import numpy as np

img = cv2.imread('C:/Users/Administrator/Desktop/1010test/19.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray = np.float32(gray)

dst = cv2.cornerHarris(gray, 2, 3, 0.20)
dst = cv2.dilate(dst, None)

img[dst > 0.01 * dst.max()] = [0, 0, 250]
cv2.imshow('dst', img)
if cv2.waitKey(0) & 0xff == 25:
    cv2.destroyAllWindows()
